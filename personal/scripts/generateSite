#!/usr/bin/env bash

# TODO
#
# verificar video de oopsla e do spg
# copy essential info from short CV (service)
# pÃ¡gina com CV curto em ingles e link pra o lattes, ao inves de 
#    linkar para o lattes direto do logo CV
# add more pdfs for articles (OK up to 2016)
# add featured publications section
# add resources to .gitignore
# fix Disqus issue, or remove it
# copy student info from Lattes, as done for publications
# add students pictures and home pages, and former students too
# progressively copy stuff from federated wiki and SPG internal links
# improve and document scripts, including this one!
#
# add error handling (abort if files not available, especially curriculo.xml, do not rm files if others have not been created!)
#

# BEFORE CALLING THIS SCRIPT
#
# Download "curriculo.xml" file from Lattes (thorugh the search CV option, not 
# the update CV option). Store it in the "files" directory.
#

#
# generating JSON from Lattes XML
#
cd lattesXml2Json
mv ../files/curriculo.xml vitaeCNPq.xml
ruby lattes2Json.rb > ../files/novoCurriculoBaixadoDoLattes.json
rm vitaeCNPq.xml

#
# merging new and old JSONs
#
cd ../jsonMerge
node jsonMerge ../files/curriculoAtual.json ../files/novoCurriculoBaixadoDoLattes.json ../files/novoCurriculoIntegrado.json
cd ../files
rm novoCurriculoBaixadoDoLattes.json
rm curriculoAnterior.json
mv curriculoAtual.json curriculoAnterior.json
mv novoCurriculoIntegrado.json curriculoAtual.json

#
# AFTER CALLING THIS SCRIPT
#
# Manually edit curriculoAtual.json removing conflicts, and adding 
#   extra information (pdf files, etc.). 
# PDF files of new articles should be added to scripts/jsonToSite/resources
# If there are new author and journal name issues, assess if it's better 
#   to solve them directly at Lattes GUI or adapting the script in lattesXml2Json
#
# After that, clean the jsonToSite/output directory and call the jsonToSite script.
#
# cd ../jsonToSite/output
# rm -R *
# node ../jsonToSite
#
# And then copy the newly generated publications to the content directory
# (which is used as the basis to generate the site)
#
# cp ../../../../content/publication/_index.md .
# rm -R ../../../../content/publication/*
# mv * ../../../../content/publication
#  
# Test the website
#
# cd ../../../../ 
# back to homepage folder
# hugo --i18n-warnings server
#
# If everything is OK (check http://localhost:1313/), generate and put the website in public
#  
# hugo
#
# And commit new website version and upload it to github.io
# public is the generated website content mapped to pauloborba.github.io
#
# cd public
# git add .
# git commit -m "new version of the website"
# git push origin master
# cd ..
#
# Finally, commit new content version and upload it to my academic fork
# homepage is my academic-kickstart fork with my website source code, 
# scripts, pdf files, and all material that is used to generate the actual
# website content.
#
# git status
# git commit -m "new version of the website"
# git push origin master
#
# Load new sitemap in https://search.google.com/search-console?resource_id=https%3A%2F%2Fpauloborba.github.io%2F
#
# Eventually update academic by calling the update_academic.sh script
# or following the instructions in https://sourcethemes.com/academic/docs/update/
# academic is mapped to the original academic repo and contains the generic 
# infrastructure for generating sites
#
# To create a post
#
# hugo new --kind post post/my-article-name
#
# To create a project
#
# hugo new --kind project project/my-project-name
#
# Further instructions on https://sourcethemes.com/academic/docs/managing-content/